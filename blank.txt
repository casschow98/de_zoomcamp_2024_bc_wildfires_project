gcloud dataproc jobs submit pyspark \
    --cluster=example-cluster \
    --region=us-west1 \
    --jars=gs://de-zoomcamp-cchow-bucket/spark-bigquery-with-dependencies_2.12-0.29.0.jar \
    gs://de-zoomcamp-cchow-bucket/transformation.py \
    -- \
    --project_id=famous-muse-426921-s5 \
    --bucket=de-zoomcamp-cchow-bucket

gcloud dataproc clusters describe example-cluster --region=us-west1

gcloud dataproc clusters create example-cluster --region=us-west1 \
    --image-version=2.0.110-debian10 \
    --master-machine-type=n1-standard-4 \
    --worker-machine-type=n1-standard-4 \
    --num-workers=2 \
    --scopes=https://www.googleapis.com/auth/bigquery,https://www.googleapis.com/auth/cloud-platform \
    --service-account=dezoomcamp-cchow-terraform@famous-muse-426921-s5.iam.gserviceaccount.com

gcloud dataproc jobs wait 6a3eb41b-a5ab-49db-b371-04dfd2801a1f \
    --project=famous-muse-426921-s5 \
    --region=us-west1

bq show --project_id=famous-muse-426921-s5 de_zoomcamp_cchow_dataset.cchow_table

gcloud compute instances describe de-zoomcamp --format='value(serviceAccounts[].scopes[])'